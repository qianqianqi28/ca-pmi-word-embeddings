{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a210718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import sqrt\n",
    "from random import Random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "#from scipy.stats.stats import spearmanr\n",
    "from scipy.stats import spearmanr\n",
    "from random import shuffle\n",
    "import math\n",
    "import random\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "#from sparsesvd import sparsesvd\n",
    "from numpy.linalg import matrix_rank\n",
    "from scipy.stats import chi2_contingency\n",
    "from matplotlib.pyplot import *\n",
    "from numpy import inf\n",
    "from scipy.linalg import svd\n",
    "from foobar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f7f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load basic matrix and elements that are neeeded for later\n",
    "cooccur_dense = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_cooccur_dense.npy\")\n",
    "vocab = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_vocab.npy\", allow_pickle=True)\n",
    "vocab = dict(enumerate(vocab.flatten(), 1))[1]\n",
    "\n",
    "test_files = ['wordsim353.txt', 'men_dataset.txt', 'mturk.txt', 'rarewords.txt', 'simlex999.txt']\n",
    "\n",
    "dim_range1 = [2, 50]\n",
    "dim_range2 = list(np.arange(100, 1001, 100))\n",
    "dim_range3 = list(np.arange(2000, 10001, 1000))\n",
    "dim_range4 = [11000]\n",
    "dim_range = [*dim_range1, *dim_range2, *dim_range3, *dim_range4]\n",
    "dim_range\n",
    "eig_weight = [0, 0.5, 1, 1.2]\n",
    "eig_weight_str = ['0', '0.5', '1', '1.2']\n",
    "bnc_rank = 11332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afbb61c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(353, 276, 0.7818696883852692),\n",
       " (3000, 1925, 0.6416666666666667),\n",
       " (287, 197, 0.686411149825784),\n",
       " (2034, 204, 0.10029498525073746),\n",
       " (999, 847, 0.8478478478478478)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To look at word pairs in BNC\n",
    "\n",
    "cooccur_vectors_words = fittingmatrixvectors(cooccur_dense)\n",
    "\n",
    "bnc_test_word_pairs = []\n",
    "\n",
    "for i in range(len(test_files)):\n",
    "    \n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[i]\n",
    "    \n",
    "    test_word_pairs_set = read_test_word_pairs_set(path_input)\n",
    "    \n",
    "    evaluate_word_pairs_create = evaluate_word_pairs(cooccur_vectors_words, test_word_pairs_set, vocab, \"cosine\")\n",
    "    \n",
    "    bnc_test_word_pairs.append((len(test_word_pairs_set), evaluate_word_pairs_create[1], float(evaluate_word_pairs_create[1]) / len(test_word_pairs_set)))\n",
    "#table 1\n",
    "bnc_test_word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c49cbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qi000005\\OneDrive - Universiteit Utrecht\\qi000005\\paper 3\\Correspondence analysis to PMI-based word embeddings\\CARME\\foobar.py:77: RuntimeWarning: divide by zero encountered in log2\n",
      "  pmi = np.log2(pmi)\n",
      "C:\\Users\\qi000005\\OneDrive - Universiteit Utrecht\\qi000005\\paper 3\\Correspondence analysis to PMI-based word embeddings\\CARME\\foobar.py:87: RuntimeWarning: divide by zero encountered in log2\n",
      "  pmi = np.log2(pmi)\n"
     ]
    }
   ],
   "source": [
    "#Evaluate TTEST, PMI, and PPMI\n",
    "\n",
    "ttest = build_ttest(cooccur_dense)\n",
    "ttest_vectors_words = fittingmatrixvectors(ttest)\n",
    "ws_score_ttest = []\n",
    "for i in range(len(test_files)):\n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[i]\n",
    "    ws_score_ttest.append((\"ttest\", test_files[i], ws_evaluate(ttest_vectors_words, vocab, mearsure = 'cosine', path = path_input)))      \n",
    "    \n",
    "\n",
    "pmi = build_count_transform(cooccur_dense, contratype = \"pmi\")\n",
    "pmi_vectors_words = fittingmatrixvectors(pmi)\n",
    "ws_score_pmi = []\n",
    "for i in range(len(test_files)):\n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[i]\n",
    "    ws_score_pmi.append((\"pmi\", test_files[i], ws_evaluate(pmi_vectors_words, vocab, mearsure = 'cosine', path = path_input)))  \n",
    "\n",
    "ppmi = build_count_transform(cooccur_dense, contratype = \"ppmi\")\n",
    "ppmi_vectors_words = fittingmatrixvectors(ppmi)\n",
    "ws_score_ppmi = []\n",
    "\n",
    "for i in range(len(test_files)):\n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[i]\n",
    "    ws_score_ppmi.append((\"ppmi\", test_files[i], ws_evaluate(ppmi_vectors_words, vocab, mearsure = 'cosine', path = path_input)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d25ae86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the evaluation of TTEST, PMI, and PPMI\n",
    "\n",
    "np.save(\"D:\\\\carme\\\\bnc\\\\table2\\\\bnc_ws_score_ttest.npy\", ws_score_ttest)  \n",
    "np.save(\"D:\\\\carme\\\\bnc\\\\table2\\\\bnc_ws_score_pmi.npy\", ws_score_pmi)  \n",
    "np.save(\"D:\\\\carme\\\\bnc\\\\table2\\\\bnc_ws_score_ppmi.npy\", ws_score_ppmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the word-context matrix of PMI, PPMI, ROOT, ROOTROOT\n",
    "\n",
    "decomposedmatrix = [\"pmi\", \"ppmi\", \"root\", \"rootroot\"]\n",
    "for i in range(len(decomposedmatrix)):\n",
    "    temp = build_count_transform(cooccur_dense, contratype = decomposedmatrix[i])\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+decomposedmatrix[i]+\".npy\", temp)\n",
    "#copy bnc_cooccur_dense and chane the name into bnc_raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6275cca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('root_ttest', 'wordsim353.txt', 0.539189142278815),\n",
       " ('root_ttest', 'men_dataset.txt', 0.2932324188288258),\n",
       " ('root_ttest', 'mturk.txt', 0.6594621929307336),\n",
       " ('root_ttest', 'rarewords.txt', 0.47734781813627786),\n",
       " ('root_ttest', 'simlex999.txt', 0.27994840678708527)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate ROOT-TTEST and save the evaluation\n",
    "\n",
    "bnc_root = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_root.npy\")\n",
    "root_ttest = build_ttest(bnc_root)\n",
    "root_ttest_vectors_words = fittingmatrixvectors(root_ttest)\n",
    "ws_score_root_ttest = []\n",
    "for i in range(len(test_files)):\n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[i]\n",
    "    ws_score_root_ttest.append((\"root_ttest\", test_files[i], ws_evaluate(root_ttest_vectors_words, vocab, mearsure = 'cosine', path = path_input)))      \n",
    "np.save(\"D:\\\\carme\\\\bnc\\\\table2\\\\bnc_ws_score_root_ttest.npy\", ws_score_root_ttest)  \n",
    "ws_score_root_ttest    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeb58a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rootroot_ttest', 'wordsim353.txt', 0.49516590917845443),\n",
       " ('rootroot_ttest', 'men_dataset.txt', 0.2630053209840326),\n",
       " ('rootroot_ttest', 'mturk.txt', 0.6159739847497702),\n",
       " ('rootroot_ttest', 'rarewords.txt', 0.4538918224648214),\n",
       " ('rootroot_ttest', 'simlex999.txt', 0.23853544432680374)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate ROOTROOT-TTEST and save the evaluation\n",
    "\n",
    "bnc_rootroot = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_rootroot.npy\")\n",
    "rootroot_ttest = build_ttest(bnc_rootroot)\n",
    "rootroot_ttest_vectors_words = fittingmatrixvectors(rootroot_ttest)\n",
    "ws_score_rootroot_ttest = []\n",
    "for i in range(len(test_files)):\n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[i]\n",
    "    ws_score_rootroot_ttest.append((\"rootroot_ttest\", test_files[i], ws_evaluate(rootroot_ttest_vectors_words, vocab, mearsure = 'cosine', path = path_input)))      \n",
    "np.save(\"D:\\\\carme\\\\bnc\\\\table2\\\\bnc_ws_score_rootroot_ttest.npy\", ws_score_rootroot_ttest)  \n",
    "ws_score_rootroot_ttest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e170e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the word-context matrix of STRATOS-TTEST\n",
    "\n",
    "decomposedmatrix = [\"rootcca\"]\n",
    "for i in range(len(decomposedmatrix)):\n",
    "    temp = build_count_transform(cooccur_dense, contratype = decomposedmatrix[i])\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+decomposedmatrix[i]+\".npy\", temp)\n",
    "#copy bnc_cooccur_dense and chane the name into bnc_raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d1fef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rootcca', 'wordsim353.txt', 0.31354467286412),\n",
       " ('rootcca', 'men_dataset.txt', 0.12972319968325272),\n",
       " ('rootcca', 'mturk.txt', 0.5252851890867198),\n",
       " ('rootcca', 'rarewords.txt', 0.19622644483481302),\n",
       " ('rootcca', 'simlex999.txt', 0.1245647519534025)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the STRATOS-TTEST and save the evaluation\n",
    "\n",
    "bnc_rootcca = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_rootcca.npy\")\n",
    "rootcca_vectors_words = fittingmatrixvectors(bnc_rootcca)\n",
    "ws_score_rootcca = []\n",
    "for i in range(len(test_files)):\n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[i]\n",
    "    ws_score_rootcca.append((\"rootcca\", test_files[i], ws_evaluate(rootcca_vectors_words, vocab, mearsure = 'cosine', path = path_input)))      \n",
    "np.save(\"D:\\\\carme\\\\bnc\\\\table2\\\\bnc_ws_score_rootcca.npy\", ws_score_rootcca)  \n",
    "ws_score_rootcca    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8412dd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pmi_g', 'wordsim353.txt', 0.22059890392876363),\n",
       " ('pmi_g', 'men_dataset.txt', 0.1710600317598314),\n",
       " ('pmi_g', 'mturk.txt', 0.41717489588729745),\n",
       " ('pmi_g', 'rarewords.txt', 0.25480494207036325),\n",
       " ('pmi_g', 'simlex999.txt', 0.11793292751302933)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the WPMI and save the evaluation\n",
    "\n",
    "\n",
    "bnc_pmi = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_pmi.npy\")\n",
    "\n",
    "beta = 1\n",
    "a = 1\n",
    "b = 1\n",
    "P = cooccur_dense / np.sum(cooccur_dense)\n",
    "sum_w = np.array(P.sum(axis = 1))\n",
    "sum_c = np.array(P.sum(axis=0)).T\n",
    "sum_c_beta = (sum_c ** (beta)) / np.sum(sum_c ** (beta)) \n",
    "sum_w_pro_root = sum_w ** (a/2)\n",
    "sum_c_pro_root = sum_c_beta ** (b/2)\n",
    "        \n",
    "sum_w_pro_root_diag = np.diag(sum_w_pro_root)\n",
    "sum_c_pro_root_diag = np.diag(sum_c_pro_root)\n",
    "  \n",
    "bnc_pmi_gsvd = sum_w_pro_root_diag @ bnc_pmi @ sum_c_pro_root_diag\n",
    "\n",
    "pmi_g_vectors_words = fittingmatrixvectors(bnc_pmi_gsvd)\n",
    "ws_score_pmi_g = []\n",
    "\n",
    "for i in range(len(test_files)):\n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[i]\n",
    "    ws_score_pmi_g.append((\"pmi_g\", test_files[i], ws_evaluate(pmi_g_vectors_words, vocab, mearsure = 'cosine', path = path_input))) \n",
    "    \n",
    "np.save(\"D:\\\\carme\\\\bnc\\\\table2\\\\bnc_ws_score_pmi_g.npy\", ws_score_pmi_g)      \n",
    "ws_score_pmi_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5000a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the PMI-SVD, PPMI-SVD, and RAW-CA, ROOT-CA, ROOTROOT-CA\n",
    "svddecomposedmatrix = [\"pmi\", \"ppmi\"]\n",
    "for i in range(len(svddecomposedmatrix)):\n",
    "    print(i)\n",
    "    temp = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\".npy\")\n",
    "    svd_u, svd_s, svd_v = svdcadense(temp, method = \"svd\")\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\"_svd_u.npy\", svd_u)\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\"_svd_s.npy\", svd_s)\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\"_svd_v.npy\", svd_v)\n",
    "    \n",
    "cadecomposedmatrix = [\"raw\", \"root\", \"rootroot\"]\n",
    "for i in range(len(cadecomposedmatrix)):\n",
    "    print(i)\n",
    "    temp = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+cadecomposedmatrix[i]+\".npy\")\n",
    "    ca_u, ca_s, ca_v = svdcadense(temp, method = \"ca\")\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+cadecomposedmatrix[i]+\"_ca_u.npy\", ca_u)\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+cadecomposedmatrix[i]+\"_ca_s.npy\", ca_s)\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+cadecomposedmatrix[i]+\"_ca_v.npy\", ca_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21abfc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Create the ROOT-CCA\n",
    "\n",
    "svddecomposedmatrix = [\"rootcca\"]\n",
    "for i in range(len(svddecomposedmatrix)):\n",
    "    print(i)\n",
    "    temp = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\".npy\")\n",
    "    svd_u, svd_s, svd_v = svdcadense(temp, method = \"svd\")\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\"_svd_u.npy\", svd_u)\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\"_svd_s.npy\", svd_s)\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\"_svd_v.npy\", svd_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate PMI-SVD, PPMI-SVD, and RAW-CA, ROOT-CA, ROOTROOT-CA\n",
    "svddecomposedmatrix = [\"pmi\", \"ppmi\"]\n",
    "\n",
    "for q in range(len(svddecomposedmatrix)):\n",
    "    print(q)\n",
    "    svd_u = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[q]+\"_svd_u.npy\")\n",
    "    svd_s = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[q]+\"_svd_s.npy\")\n",
    "    svd_u = np.fliplr(svd_u)\n",
    "    svd_s = svd_s[::-1]\n",
    "    svd_ws_score_cos_all = list()\n",
    "    for k in range(len(test_files)):\n",
    "        print(\"k = \" + str(test_files[k]))\n",
    "        test_type = test_files[k]\n",
    "    \n",
    "        path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[k]\n",
    "\n",
    "        svd_ws_score_cos = pd.DataFrame()\n",
    "    \n",
    "        for i in range(len(eig_weight)):\n",
    "            print(\"i = \" + str(eig_weight[i]))\n",
    "    \n",
    "            svd_w = svd_u * np.power(svd_s, eig_weight[i])\n",
    "\n",
    "            svd_score = []\n",
    "\n",
    "            for j in dim_range:\n",
    "                vectors_words = svdvectors(svd_w, max_dim = svd_u.shape[1], dim = j)\n",
    "        \n",
    "                svd_score_dim = ws_evaluate(vectors_words, vocab, mearsure = 'cosine', path = path_input)\n",
    "            \n",
    "                svd_score.append(svd_score_dim)\n",
    "\n",
    "            svd_ws_score_cos[eig_weight_str[i]] = svd_score\n",
    "        svd_ws_score_cos_all.append(svd_ws_score_cos)\n",
    "    \n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\bnc_\"+svddecomposedmatrix[q]+\"_svd_ws_score_cos_all.npy\", svd_ws_score_cos_all)\n",
    "\n",
    "    \n",
    "cadecomposedmatrix = [\"raw\", \"root\", \"rootroot\"]\n",
    "\n",
    "for q in range(len(cadecomposedmatrix)):\n",
    "    print(q)\n",
    "    ca_u = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+cadecomposedmatrix[q]+\"_ca_u.npy\")\n",
    "    ca_s = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+cadecomposedmatrix[q]+\"_ca_s.npy\")\n",
    "    ca_u = np.fliplr(ca_u)\n",
    "    ca_s = ca_s[::-1]\n",
    "    ca_ws_score_cos_all = list()\n",
    "    for k in range(len(test_files)):\n",
    "        print(\"k = \" + str(test_files[k]))\n",
    "        test_type = test_files[k]\n",
    "    \n",
    "        path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[k]\n",
    "\n",
    "        ca_ws_score_cos = pd.DataFrame()\n",
    "    \n",
    "        for i in range(len(eig_weight)):\n",
    "            print(\"i = \" + str(eig_weight[i]))\n",
    "    \n",
    "            ca_w = ca_u * np.power(ca_s, eig_weight[i])\n",
    "\n",
    "            ca_score = []\n",
    "\n",
    "            for j in dim_range:\n",
    "                vectors_words = svdvectors(ca_w, max_dim = ca_u.shape[1], dim = j)\n",
    "        \n",
    "                ca_score_dim = ws_evaluate(vectors_words, vocab, mearsure = 'cosine', path = path_input)\n",
    "            \n",
    "                ca_score.append(ca_score_dim)\n",
    "\n",
    "            ca_ws_score_cos[eig_weight_str[i]] = ca_score\n",
    "        ca_ws_score_cos_all.append(ca_ws_score_cos)\n",
    "    \n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\bnc_\"+cadecomposedmatrix[q]+\"_ca_ws_score_cos_all.npy\", ca_ws_score_cos_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b63310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "k = wordsim353.txt\n",
      "i = 0\n",
      "i = 0.5\n",
      "i = 1\n",
      "i = 1.2\n",
      "k = men_dataset.txt\n",
      "i = 0\n",
      "i = 0.5\n",
      "i = 1\n",
      "i = 1.2\n",
      "k = mturk.txt\n",
      "i = 0\n",
      "i = 0.5\n",
      "i = 1\n",
      "i = 1.2\n",
      "k = rarewords.txt\n",
      "i = 0\n",
      "i = 0.5\n",
      "i = 1\n",
      "i = 1.2\n",
      "k = simlex999.txt\n",
      "i = 0\n",
      "i = 0.5\n",
      "i = 1\n",
      "i = 1.2\n"
     ]
    }
   ],
   "source": [
    "#create and evaluate ROOT-CCA\n",
    "svddecomposedmatrix = [\"rootcca\"]\n",
    "\n",
    "for q in range(len(svddecomposedmatrix)):\n",
    "    print(q)\n",
    "    svd_u = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[q]+\"_svd_u.npy\")\n",
    "    svd_s = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[q]+\"_svd_s.npy\")\n",
    "    svd_u = np.fliplr(svd_u)\n",
    "    svd_s = svd_s[::-1]\n",
    "    svd_ws_score_cos_all = list()\n",
    "    for k in range(len(test_files)):\n",
    "        print(\"k = \" + str(test_files[k]))\n",
    "        test_type = test_files[k]\n",
    "    \n",
    "        path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[k]\n",
    "\n",
    "        svd_ws_score_cos = pd.DataFrame()\n",
    "    \n",
    "        for i in range(len(eig_weight)):\n",
    "            print(\"i = \" + str(eig_weight[i]))\n",
    "    \n",
    "            svd_w = svd_u * np.power(svd_s, eig_weight[i])\n",
    "\n",
    "            svd_score = []\n",
    "\n",
    "            for j in dim_range:\n",
    "                vectors_words = svdvectors(svd_w, max_dim = svd_u.shape[1], dim = j)\n",
    "        \n",
    "                svd_score_dim = ws_evaluate(vectors_words, vocab, mearsure = 'cosine', path = path_input)\n",
    "            \n",
    "                svd_score.append(svd_score_dim)\n",
    "\n",
    "            svd_ws_score_cos[eig_weight_str[i]] = svd_score\n",
    "        svd_ws_score_cos_all.append(svd_ws_score_cos)\n",
    "    \n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\bnc_\"+svddecomposedmatrix[q]+\"_svd_ws_score_cos_all.npy\", svd_ws_score_cos_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a1f1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "11332\n",
      "1\n",
      "11332\n",
      "2\n",
      "11332\n",
      "3\n",
      "11332\n",
      "4\n",
      "11332\n"
     ]
    }
   ],
   "source": [
    "#Calculate the rank of RAW, PMI, PPMI, ROOT, ROOTROOT\n",
    "svddecomposedmatrix = [\"raw\", \"pmi\", \"ppmi\", \"root\", \"rootroot\"]\n",
    "for i in range(len(svddecomposedmatrix)):\n",
    "    print(i)\n",
    "    temp = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\".npy\")\n",
    "    print(matrix_rank(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7fc2e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "11332\n"
     ]
    }
   ],
   "source": [
    "#Calculate the rank of STRATOS-TTEST\n",
    "\n",
    "svddecomposedmatrix = [\"rootcca\"]\n",
    "for i in range(len(svddecomposedmatrix)):\n",
    "    print(i)\n",
    "    temp = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\".npy\")\n",
    "    print(matrix_rank(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c83b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and evaluate PMI-GSVD\n",
    "\n",
    "svddecomposedmatrix = [\"pmi\"]\n",
    "for i in range(len(svddecomposedmatrix)):\n",
    "    print(i)\n",
    "    temp = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\".npy\")\n",
    "    gsvd_u, gsvd_s, gsvd_v = build_gsvd(temp, cooccur_dense, 1, 1)\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\"_gsvd_u.npy\", gsvd_u)\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\"_gsvd_s.npy\", gsvd_s)\n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[i]+\"_gsvd_v.npy\", gsvd_v)\n",
    "\n",
    "\n",
    "svddecomposedmatrix = [\"pmi\"]\n",
    "\n",
    "for q in range(len(svddecomposedmatrix)):\n",
    "    print(q)\n",
    "    svd_u = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[q]+\"_gsvd_u.npy\")\n",
    "    svd_s = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_\"+svddecomposedmatrix[q]+\"_gsvd_s.npy\")\n",
    "    gsvd_ws_score_cos_all = list()\n",
    "    for k in range(len(test_files)):\n",
    "        print(\"k = \" + str(test_files[k]))\n",
    "        test_type = test_files[k]\n",
    "    \n",
    "        path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[k]\n",
    "\n",
    "        svd_ws_score_cos = pd.DataFrame()\n",
    "    \n",
    "        for i in range(len(eig_weight)):\n",
    "            print(\"i = \" + str(eig_weight[i]))\n",
    "    \n",
    "            svd_w = svd_u * np.power(svd_s, eig_weight[i])\n",
    "\n",
    "            svd_score = []\n",
    "\n",
    "            for j in dim_range:\n",
    "                vectors_words = svdvectorsincrease(svd_w, dim = j)\n",
    "        \n",
    "                svd_score_dim = ws_evaluate(vectors_words, vocab, mearsure = 'cosine', path = path_input)\n",
    "            \n",
    "                svd_score.append(svd_score_dim)\n",
    "\n",
    "            svd_ws_score_cos[eig_weight_str[i]] = svd_score\n",
    "        gsvd_ws_score_cos_all.append(svd_ws_score_cos)\n",
    "    \n",
    "    np.save(\"D:\\\\carme\\\\bnc\\\\bnc_\"+svddecomposedmatrix[q]+\"_gsvd_ws_score_cos_all.npy\", gsvd_ws_score_cos_all)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1872573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create TTEST, WPMI, ROOT-TTEST, ROOTROOT-TTEST\n",
    "\n",
    "bnc_ttest = build_ttest(bnc_cooccur_dense)\n",
    "np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_ttest.npy\", bnc_ttest)\n",
    "\n",
    "bnc_pmi = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_pmi.npy\")\n",
    "\n",
    "#bnc_ppmi = np.where(bnc_pmi < 0, 0, bnc_pmi)\n",
    "\n",
    "beta = 1\n",
    "a = 1\n",
    "b = 1\n",
    "P = bnc_cooccur_dense / np.sum(bnc_cooccur_dense)\n",
    "sum_w = np.array(P.sum(axis = 1))\n",
    "sum_c = np.array(P.sum(axis=0)).T\n",
    "sum_c_beta = (sum_c ** (beta)) / np.sum(sum_c ** (beta)) \n",
    "sum_w_pro_root = sum_w ** (a/2)\n",
    "sum_c_pro_root = sum_c_beta ** (b/2)\n",
    "        \n",
    "sum_w_pro_root_diag = np.diag(sum_w_pro_root)\n",
    "sum_c_pro_root_diag = np.diag(sum_c_pro_root)\n",
    "  \n",
    "bnc_pmi_gsvd = sum_w_pro_root_diag @ bnc_pmi @ sum_c_pro_root_diag\n",
    "np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_pmi_gsvd.npy\", bnc_pmi_gsvd)\n",
    "\n",
    "\n",
    "\n",
    "bnc_root = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_root.npy\")\n",
    "bnc_root_ttest = build_ttest(bnc_root)\n",
    "np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_root_ttest.npy\", bnc_root_ttest)\n",
    "\n",
    "\n",
    "bnc_rootroot = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_rootroot.npy\")\n",
    "bnc_rootroot_ttest = build_ttest(bnc_rootroot)\n",
    "np.save(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_rootroot_ttest.npy\", bnc_rootroot_ttest)\n",
    "\n",
    "#bnc_rootcca = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_rootcca.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
