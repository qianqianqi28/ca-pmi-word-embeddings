{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b899b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import sqrt\n",
    "from random import Random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "#from scipy.stats.stats import spearmanr\n",
    "from scipy.stats import spearmanr\n",
    "from random import shuffle\n",
    "import math\n",
    "import random\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "#from sparsesvd import sparsesvd\n",
    "from numpy.linalg import matrix_rank\n",
    "from scipy.stats import chi2_contingency\n",
    "from matplotlib.pyplot import *\n",
    "from numpy import inf\n",
    "from scipy.linalg import svd\n",
    "from foobar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a4a39170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the verctors from GloVe of Text8 \n",
    "dim = [\"200\", \"300\", \"400\", \"500\", \"600\"]\n",
    "test_files = ['wordsim353.txt', 'men_dataset.txt', 'mturk.txt', 'rarewords.txt', 'simlex999.txt']\n",
    "text8_ws_score_glove = list()\n",
    "for k in range(len(test_files)):\n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[k]\n",
    "    svd_score = []\n",
    "    for i in dim:\n",
    "        #glovevector = loadglovemodel(\"D:\\\\Correspondence analysis to PMI-based word embeddings\\\\GloVe-text8\\\\vectors\"+i+\".txt\")\n",
    "        glovevector = loadglovemodel(\"D:\\\\carme\\\\text8\\\\GloVe-master\\\\GloVe-master\\\\vectors\"+i+\".txt\")\n",
    "        #For Glove, there is extra word (<unk>) vector which is not in vacobulary. Therefore, we delete this word in word vectors: list(glovevector.keys())[-1]\n",
    "        orderedNames = list(glovevector.keys())[:-1]\n",
    "        glovematrix = np.array([glovevector[i] for i in orderedNames])\n",
    "        #glovevocab = loadglovevocab(\"D:\\\\Correspondence analysis to PMI-based word embeddings\\\\GloVe-text8\\\\vocab.txt\")\n",
    "        glovevocab = loadglovevocab(\"D:\\\\carme\\\\text8\\\\GloVe-master\\\\GloVe-master\\\\vocab.txt\")\n",
    "        prices = range(0, glovematrix.shape[0])\n",
    "        vocabsum =  list(glovevocab.values())\n",
    "        vocabtuple = merge(prices, vocabsum)\n",
    "        vocab = dict(zip(glovevocab.keys(), vocabtuple))\n",
    "\n",
    "        glovematrix_vectors_words = fittingmatrixvectors(glovematrix)\n",
    "\n",
    "        svd_score.append(ws_evaluate(glovematrix_vectors_words, vocab, mearsure = 'cosine', path = path_input))\n",
    "    text8_ws_score_glove.append(svd_score)\n",
    "np.save(\"D:\\\\carme\\\\text8\\\\text8_ws_score_glove.npy\", text8_ws_score_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8758a63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.421724234956006,\n",
       "  0.4133850471938503,\n",
       "  0.415495605022818,\n",
       "  0.41093599834870653,\n",
       "  0.41102972563592133],\n",
       " [0.16767423423510677,\n",
       "  0.17464811894936197,\n",
       "  0.17390351884694585,\n",
       "  0.17358549933867332,\n",
       "  0.17285304383308447],\n",
       " [0.494036134284251,\n",
       "  0.48743018474884037,\n",
       "  0.4971837305368383,\n",
       "  0.4979369966834748,\n",
       "  0.5015415558678225],\n",
       " [0.18051858706281598,\n",
       "  0.17234621852333784,\n",
       "  0.18081112902025068,\n",
       "  0.17752490769840132,\n",
       "  0.17527442421156472],\n",
       " [0.1477221940769442,\n",
       "  0.14558290458716772,\n",
       "  0.14700907667348942,\n",
       "  0.14790224920445078,\n",
       "  0.14494012832296174]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text8_ws_score_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e260b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Glove there is extra word (<unk>) vector which is not in vacobulary. Therefore, we delete this word vector.\n",
    "list(glovevector.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8926fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "glovevector = loadglovemodel(\"D:\\\\carme\\\\text8\\\\GloVe-master\\\\GloVe-master\\\\vectors200.txt\")\n",
    "orderedNames = list(glovevector.keys())[:-1]\n",
    "glovematrix = np.array([glovevector[i] for i in orderedNames])\n",
    "glovevocab = loadglovevocab(\"D:\\\\carme\\\\text8\\\\GloVe-master\\\\GloVe-master\\\\vocab.txt\")\n",
    "prices = range(0, glovematrix.shape[0])\n",
    "vocabsum =  list(glovevocab.values())\n",
    "vocabtuple = merge(prices, vocabsum)\n",
    "vocab = dict(zip(glovevocab.keys(), vocabtuple))\n",
    "glovematrix_vectors_words = fittingmatrixvectors(glovematrix)\n",
    "glove_vocab = vocab.copy()\n",
    "svd_vocab = np.load(\"D:\\\\carme\\\\text8\\\\decomposed matrix\\\\vocab.npy\", allow_pickle=True)\n",
    "svd_vocab = dict(enumerate(svd_vocab.flatten(), 1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7d499e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(353, 277, 0.7847025495750708),\n",
       " (3000, 1544, 0.5146666666666667),\n",
       " (287, 221, 0.7700348432055749),\n",
       " (2034, 205, 0.1007866273352999),\n",
       " (999, 726, 0.7267267267267268)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To look at word pairs in Text8\n",
    "\n",
    "test_files = ['wordsim353.txt', 'men_dataset.txt', 'mturk.txt', 'rarewords.txt', 'simlex999.txt']\n",
    "\n",
    "text8_test_word_pairs = []\n",
    "\n",
    "for i in range(len(test_files)):\n",
    "    \n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[i]\n",
    "    \n",
    "    test_word_pairs_set = read_test_word_pairs_set(path_input)\n",
    "    \n",
    "    evaluate_word_pairs_create = evaluate_word_pairs(glovematrix_vectors_words, test_word_pairs_set, glove_vocab, \"cosine\")\n",
    "    \n",
    "    text8_test_word_pairs.append((len(test_word_pairs_set), evaluate_word_pairs_create[1], float(evaluate_word_pairs_create[1]) / len(test_word_pairs_set)))\n",
    "#table 1\n",
    "text8_test_word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1bd45e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both the dictionaries are equal\n"
     ]
    }
   ],
   "source": [
    "#To detect whether the vocab in GloVe is the same as that in SVD\n",
    "if len(glove_vocab)!=len(svd_vocab):\n",
    "    print(\"Not equal\")\n",
    "else:\n",
    "    flag=0\n",
    "    for i in glove_vocab:\n",
    "        if glove_vocab.get(i)[1]!=svd_vocab.get(i)[1]:\n",
    "            flag=1\n",
    "            break\n",
    "    if flag==0:\n",
    "        print(\"Both the dictionaries are equal\")\n",
    "    else:\n",
    "        print(\"Both the dictionaries are not equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5677a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11814, array(100.))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vocab.get(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85d42a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11371, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_vocab.get(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "336a97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the verctors from GloVe of BNC\n",
    "dim = [\"200\", \"300\", \"400\", \"500\", \"600\"]\n",
    "test_files = ['wordsim353.txt', 'men_dataset.txt', 'mturk.txt', 'rarewords.txt', 'simlex999.txt']\n",
    "bnc_ws_score_glove = list()\n",
    "for k in range(len(test_files)):\n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[k]\n",
    "    svd_score = []\n",
    "    for i in dim:\n",
    "        glovevector = loadglovemodel(\"D:\\\\carme\\\\bnc\\\\GloVe-master\\\\GloVe-master\\\\vectors\"+i+\".txt\")\n",
    "        #For Glove, there is extra word (<unk>) vector which is not in vacobulary. Therefore, we delete this word in word vectors: list(glovevector.keys())[-1]\n",
    "        orderedNames = list(glovevector.keys())[:-1]\n",
    "        glovematrix = np.array([glovevector[i] for i in orderedNames])\n",
    "        glovevocab = loadglovevocab(\"D:\\\\carme\\\\bnc\\\\GloVe-master\\\\GloVe-master\\\\vocab.txt\")\n",
    "        prices = range(0, glovematrix.shape[0])\n",
    "        vocabsum =  list(glovevocab.values())\n",
    "        vocabtuple = merge(prices, vocabsum)\n",
    "        vocab = dict(zip(glovevocab.keys(), vocabtuple))\n",
    "\n",
    "        glovematrix_vectors_words = fittingmatrixvectors(glovematrix)\n",
    "\n",
    "        svd_score.append(ws_evaluate(glovematrix_vectors_words, vocab, mearsure = 'cosine', path = path_input))\n",
    "    bnc_ws_score_glove.append(svd_score)\n",
    "np.save(\"D:\\\\carme\\\\bnc\\\\bnc_ws_score_glove.npy\", bnc_ws_score_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0ec11d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Glove there is extra word (<unk>) vector which is not in vacobulary. Therefore, we delete this word vector.\n",
    "list(glovevector.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63794647",
   "metadata": {},
   "outputs": [],
   "source": [
    "glovevector = loadglovemodel(\"D:\\\\carme\\\\bnc\\\\GloVe-master\\\\GloVe-master\\\\vectors200.txt\")\n",
    "orderedNames = list(glovevector.keys())[:-1]\n",
    "glovematrix = np.array([glovevector[i] for i in orderedNames])\n",
    "glovevocab = loadglovevocab(\"D:\\\\carme\\\\bnc\\\\GloVe-master\\\\GloVe-master\\\\vocab.txt\")\n",
    "prices = range(0, glovematrix.shape[0])\n",
    "vocabsum =  list(glovevocab.values())\n",
    "vocabtuple = merge(prices, vocabsum)\n",
    "vocab = dict(zip(glovevocab.keys(), vocabtuple))\n",
    "glove_vocab = vocab.copy()\n",
    "svd_vocab = np.load(\"D:\\\\carme\\\\bnc\\\\decomposed matrix\\\\bnc_vocab.npy\", allow_pickle=True)\n",
    "svd_vocab = dict(enumerate(svd_vocab.flatten(), 1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "567f028c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(353, 276, 0.7818696883852692),\n",
       " (3000, 1925, 0.6416666666666667),\n",
       " (287, 197, 0.686411149825784),\n",
       " (2034, 204, 0.10029498525073746),\n",
       " (999, 847, 0.8478478478478478)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To look at word pairs in BNC\n",
    "\n",
    "test_files = ['wordsim353.txt', 'men_dataset.txt', 'mturk.txt', 'rarewords.txt', 'simlex999.txt']\n",
    "\n",
    "bnc_test_word_pairs = []\n",
    "\n",
    "for i in range(len(test_files)):\n",
    "    \n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[i]\n",
    "    \n",
    "    test_word_pairs_set = read_test_word_pairs_set(path_input)\n",
    "    \n",
    "    evaluate_word_pairs_create = evaluate_word_pairs(glovematrix_vectors_words, test_word_pairs_set, glove_vocab, \"cosine\")\n",
    "    \n",
    "    bnc_test_word_pairs.append((len(test_word_pairs_set), evaluate_word_pairs_create[1], float(evaluate_word_pairs_create[1]) / len(test_word_pairs_set)))\n",
    "#table 1\n",
    "bnc_test_word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42b65c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both the dictionaries are equal\n"
     ]
    }
   ],
   "source": [
    "if len(glove_vocab)!=len(svd_vocab):\n",
    "    print(\"Not equal\")\n",
    "else:\n",
    "    flag=0\n",
    "    for i in glove_vocab:\n",
    "        if i.isascii():\n",
    "            if glove_vocab.get(i)[1]!=svd_vocab.get(i)[1]:\n",
    "                flag=1\n",
    "                break\n",
    "    if flag==0:\n",
    "        print(\"Both the dictionaries are equal\")\n",
    "    else:\n",
    "        print(\"Both the dictionaries are not equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f04e765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "non_ascii_glove = [ ]\n",
    "for i in glove_vocab:\n",
    "    if not i.isascii():\n",
    "        non_ascii_glove.append(i)\n",
    "print(len(non_ascii_glove))\n",
    "\n",
    "non_ascii_glove_list = list()\n",
    "\n",
    "for i in non_ascii_glove:\n",
    "    non_ascii_glove_list.append(glove_vocab.get(i)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2340b8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "non_ascii_svd = [ ]\n",
    "for i in svd_vocab:\n",
    "    if not i.isascii():\n",
    "        non_ascii_svd.append(i)\n",
    "print(len(non_ascii_svd))\n",
    "\n",
    "non_ascii_svd_list = list()\n",
    "\n",
    "for i in non_ascii_svd:\n",
    "    non_ascii_svd_list.append(svd_vocab.get(i)[1])\n",
    "non_ascii_svd_list.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "908cf847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 0\n",
    "for i in range(len(non_ascii_svd)):\n",
    "    if non_ascii_glove_list[i] == non_ascii_svd_list[i]:\n",
    "        j = j+1\n",
    "j"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
