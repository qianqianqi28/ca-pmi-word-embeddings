{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "399d32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import sqrt\n",
    "from random import Random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "#from scipy.stats.stats import spearmanr\n",
    "from scipy.stats import spearmanr\n",
    "from random import shuffle\n",
    "import math\n",
    "import random\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "#from sparsesvd import sparsesvd\n",
    "from numpy.linalg import matrix_rank\n",
    "from scipy.stats import chi2_contingency\n",
    "from matplotlib.pyplot import *\n",
    "from numpy import inf\n",
    "from scipy.linalg import svd\n",
    "from foobar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee1111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the verctors from SGNS of Text8 \n",
    "\n",
    "dim = [\"200\", \"300\", \"400\", \"500\", \"600\"]\n",
    "test_files = ['wordsim353.txt', 'men_dataset.txt', 'mturk.txt', 'rarewords.txt', 'simlex999.txt']\n",
    "sgnsvocab = loadglovevocab(\"D:\\\\carme\\\\text8\\\\source-archive\\\\word2vec\\\\trunk\\\\vocabglo.txt\")\n",
    "text8_ws_score_sgns = list()\n",
    "for k in range(len(test_files)):\n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[k]\n",
    "    svd_score = []\n",
    "    for i in dim:\n",
    "        #sgnsvector = loadglovemodel(\"D:\\\\Correspondence analysis to PMI-based word embeddings\\\\word2vec-text8\\\\trunk\\\\vectorsvocglo\"+i+\".txt\")\n",
    "        sgnsvector = loadglovemodel(\"D:\\\\carme\\\\text8\\\\source-archive\\\\word2vec\\\\trunk\\\\vectorsvocglo\"+i+\".txt\")\n",
    "        orderedNames = list(sgnsvector.keys())[1:]\n",
    "        sgnsmatrix = np.array([sgnsvector[i] for i in orderedNames])\n",
    "        #sgnsvocab = loadglovevocab(\"D:\\\\Correspondence analysis to PMI-based word embeddings\\\\word2vec-text8\\\\trunk\\\\vocabvocglo\"+i+\".txt\")\n",
    "        prices = range(0, sgnsmatrix.shape[0])\n",
    "        vocabsum =  list(sgnsvocab.values())\n",
    "        vocabtuple = merge(prices, vocabsum)\n",
    "        vocab = dict(zip(sgnsvocab.keys(), vocabtuple))\n",
    "        sgnsmatrix_vectors_words = fittingmatrixvectors(sgnsmatrix)\n",
    "        svd_score.append(ws_evaluate(sgnsmatrix_vectors_words, vocab, mearsure = 'cosine', path = path_input))\n",
    "    text8_ws_score_sgns.append(svd_score)\n",
    "\n",
    "np.save(\"D:\\\\carme\\\\text8\\\\text8_ws_score_sgns.npy\", text8_ws_score_sgns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00be9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the verctors from SGNS of BNC \n",
    "\n",
    "dim = [\"200\", \"300\", \"400\", \"500\", \"600\"]\n",
    "test_files = ['wordsim353.txt', 'men_dataset.txt', 'mturk.txt', 'rarewords.txt', 'simlex999.txt']\n",
    "sgnsvocab = loadglovevocab(\"D:\\\\carme\\\\bnc\\\\source-archive\\\\word2vec\\\\trunk\\\\vocabglo.txt\")\n",
    "\n",
    "bnc_ws_score_sgns = list()\n",
    "for k in range(len(test_files)):\n",
    "    path_input = \"D:\\\\carme\\\\test dataset\\\\similarities\\\\\"+test_files[k]\n",
    "    svd_score = []\n",
    "    for i in dim:\n",
    "        sgnsvector = loadglovemodel(\"D:\\\\carme\\\\bnc\\\\source-archive\\\\word2vec\\\\trunk\\\\vectorsvocglo\"+i+\".txt\")\n",
    "        orderedNames = list(sgnsvector.keys())[1:]\n",
    "        sgnsmatrix = np.array([sgnsvector[i] for i in orderedNames])\n",
    "        prices = range(0, sgnsmatrix.shape[0])\n",
    "        vocabsum =  list(sgnsvocab.values())\n",
    "        vocabtuple = merge(prices, vocabsum)\n",
    "        vocab = dict(zip(sgnsvocab.keys(), vocabtuple))\n",
    "        sgnsmatrix_vectors_words = fittingmatrixvectors(sgnsmatrix)\n",
    "        svd_score.append(ws_evaluate(sgnsmatrix_vectors_words, vocab, mearsure = 'cosine', path = path_input))\n",
    "    bnc_ws_score_sgns.append(svd_score)\n",
    "\n",
    "np.save(\"D:\\\\carme\\\\bnc\\\\bnc_ws_score_sgns.npy\", bnc_ws_score_sgns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
